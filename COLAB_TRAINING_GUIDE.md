# CLaRa Colab Training Guide

å®Œæ•´çš„ Google Colab è®­ç»ƒæ•™ç¨‹ - ä½¿ç”¨åˆæˆæ•°æ®åœ¨äº‘ç«¯è®­ç»ƒ CLaRa æ¨¡å‹

---

## ğŸ“– ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [ç¡¬ä»¶è¦æ±‚](#ç¡¬ä»¶è¦æ±‚)
- [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [åˆ†é˜¶æ®µè®­ç»ƒ](#åˆ†é˜¶æ®µè®­ç»ƒ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ‰“å¼€ Notebook

å°† `training_colab_complete.ipynb` ä¸Šä¼ åˆ° Google Colabï¼š

**æ–¹æ³• Aï¼šç›´æ¥ä¸Šä¼ **
1. è®¿é—® [Google Colab](https://colab.research.google.com)
2. ç‚¹å‡» "æ–‡ä»¶" â†’ "ä¸Šä¼ ç¬”è®°æœ¬"
3. é€‰æ‹© `training_colab_complete.ipynb`

**æ–¹æ³• Bï¼šé€šè¿‡ GitHub**
1. å°† notebook æ¨é€åˆ° GitHub
2. åœ¨ Colab ä¸­é€‰æ‹© "GitHub" æ ‡ç­¾
3. è¾“å…¥ä»“åº“ URL å¹¶åŠ è½½

### 2. é…ç½®è¿è¡Œæ—¶

**é‡è¦ï¼šå¿…é¡»ä½¿ç”¨ GPU è¿è¡Œæ—¶**

1. ç‚¹å‡» "è¿è¡Œæ—¶" â†’ "æ›´æ”¹è¿è¡Œæ—¶ç±»å‹"
2. ç¡¬ä»¶åŠ é€Ÿå™¨ï¼šé€‰æ‹© **GPU**ï¼ˆT4ã€V100 æˆ– A100ï¼‰
3. è¿è¡Œæ—¶é…ç½®ï¼šé€‰æ‹© **High-RAM**ï¼ˆæ¨èï¼‰
4. ç‚¹å‡» "ä¿å­˜"

### 3. ä¾æ¬¡æ‰§è¡Œ

æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰å•å…ƒæ ¼ï¼š
- ç‚¹å‡» "è¿è¡Œæ—¶" â†’ "å…¨éƒ¨è¿è¡Œ"
- æˆ–æŒ‰ `Ctrl+F9` / `Cmd+F9`

**é¢„è®¡æ€»æ—¶é—´ï¼š**
- T4 GPUï¼š1-2 å°æ—¶
- V100 GPUï¼š45-90 åˆ†é’Ÿ
- A100 GPUï¼š30-60 åˆ†é’Ÿ

---

## ğŸ’» ç¡¬ä»¶è¦æ±‚

### GPU é…ç½®å¯¹æ¯”

| GPU å‹å· | æ˜¾å­˜ | è®­ç»ƒé€Ÿåº¦ | æ‰¹æ¬¡å¤§å° | Colab å¯ç”¨æ€§ |
|---------|------|---------|---------|------------|
| T4 | 16GB | åŸºå‡† (1x) | å° (32) | âœ… å…è´¹ç‰ˆ |
| V100 | 16/32GB | å¿« (2x) | ä¸­ (64) | ğŸ’° Pro |
| A100 | 40/80GB | å¾ˆå¿« (4x) | å¤§ (128) | ğŸ’° Pro+ |

### æ¨èé…ç½®

**å¿«é€Ÿæµ‹è¯•**ï¼ˆå…è´¹ï¼‰
- GPU: T4
- RAM: æ ‡å‡† (12GB)
- è®­ç»ƒæ ·æœ¬æ•°: 200-500
- ç”¨é€”: æµ‹è¯•æµç¨‹ã€éªŒè¯æ•°æ®

**æ­£å¼è®­ç»ƒ**ï¼ˆProï¼‰
- GPU: V100 æˆ– A100
- RAM: High-RAM (25GB)
- è®­ç»ƒæ ·æœ¬æ•°: 1000+
- ç”¨é€”: å®Œæ•´è®­ç»ƒã€ç”Ÿäº§æ¨¡å‹

---

## ğŸ“Š è®­ç»ƒæµç¨‹

### å®Œæ•´æµç¨‹å›¾

```mermaid
graph TD
    A[1. ç¯å¢ƒæ£€æŸ¥] --> B[2. å®‰è£…ä¾èµ–]
    B --> C[3. ä¸‹è½½ä»£ç ]
    C --> D[4. å‡†å¤‡æ•°æ®]
    D --> E[5. Stage 1: å‹ç¼©é¢„è®­ç»ƒ]
    E --> F[6. Stage 2: æŒ‡ä»¤å¾®è°ƒ]
    F --> G[7. Stage 3: ç«¯åˆ°ç«¯è®­ç»ƒ]
    G --> H[8. æ¨¡å‹æ¨ç†æµ‹è¯•]
    H --> I[9. å¯¼å‡ºæ¨¡å‹]
```

### å„é˜¶æ®µè¯¦æƒ…

#### Stage 1: å‹ç¼©é¢„è®­ç»ƒ (Compression Pretraining)

**ç›®æ ‡ï¼š** è®­ç»ƒå‹ç¼©å™¨ï¼Œå°†æ–‡æ¡£å‹ç¼©ä¸ºè¿ç»­æ½œåœ¨è¡¨ç¤º

**è¾“å…¥æ•°æ®æ ¼å¼ï¼š** `pretrain_data.jsonl`
```json
{
  "data_type": "qa",
  "question": ["é—®é¢˜æ–‡æœ¬"],
  "answers": ["ç­”æ¡ˆæ–‡æœ¬"],
  "docs": ["æ–‡æ¡£å†…å®¹"]
}
```

**å…³é”®å‚æ•°ï¼š**
- `--stage stage1`
- `--compress_rate 32`ï¼ˆ32å€å‹ç¼©ï¼‰
- `--qa_loss`ï¼ˆQA æŸå¤±ï¼‰
- `--mse_loss`ï¼ˆMSE æŸå¤±ï¼‰

**è¾“å‡ºï¼š** `/content/checkpoints/clara_stage1/`

#### Stage 2: æŒ‡ä»¤å¾®è°ƒ (Instruction Tuning)

**ç›®æ ‡ï¼š** åœ¨ä¸‹æ¸¸ QA ä»»åŠ¡ä¸Šå¾®è°ƒå‹ç¼©å™¨

**è¾“å…¥æ•°æ®æ ¼å¼ï¼š** `instruction_data.jsonl`
```json
{
  "question": "é—®é¢˜æ–‡æœ¬",
  "docs": ["æ–‡æ¡£1", "æ–‡æ¡£2"],
  "gold_answer": "å‚è€ƒç­”æ¡ˆ"
}
```

**å…³é”®å‚æ•°ï¼š**
- `--stage stage2`
- `--ckpt_path` æŒ‡å‘ Stage 1 æ£€æŸ¥ç‚¹

**è¾“å‡ºï¼š** `/content/checkpoints/clara_stage2/`

#### Stage 3: ç«¯åˆ°ç«¯è®­ç»ƒ (End-to-End Training)

**ç›®æ ‡ï¼š** è”åˆè®­ç»ƒé‡æ’åºå™¨å’Œç”Ÿæˆå™¨

**è¾“å…¥æ•°æ®æ ¼å¼ï¼š** `end_to_end_data.jsonl`ï¼ˆä¸ Stage 2 ç›¸åŒï¼‰

**å…³é”®å‚æ•°ï¼š**
- `--stage stage3`
- `--generation_top_k 5`ï¼ˆtop-k æ£€ç´¢ï¼‰
- `--ckpt_path` æŒ‡å‘ Stage 2 æ£€æŸ¥ç‚¹

**è¾“å‡ºï¼š** `/content/checkpoints/clara_stage3_final/` ï¼ˆæœ€ç»ˆæ¨¡å‹ï¼‰

---

## ğŸ“ æ•°æ®å‡†å¤‡

### é€‰é¡¹ 1ï¼šä½¿ç”¨ç¤ºä¾‹æ•°æ®ï¼ˆæ¨èç”¨äºé¦–æ¬¡è¿è¡Œï¼‰

Notebook å·²åŒ…å«ç¤ºä¾‹æ•°æ®ï¼š
- `example/pretrain_data.jsonl` - é¢„è®­ç»ƒæ•°æ®
- `example/instruction_data.jsonl` - æŒ‡ä»¤æ•°æ®
- `example/end_to_end_data.jsonl` - ç«¯åˆ°ç«¯æ•°æ®

**ä¼˜ç‚¹ï¼š** æ— éœ€å‡†å¤‡ï¼Œç›´æ¥è®­ç»ƒ
**ç¼ºç‚¹ï¼š** æ•°æ®é‡å°ï¼Œä»…ä¾›æµ‹è¯•

### é€‰é¡¹ 2ï¼šä½¿ç”¨è‡ªå·±çš„åˆæˆæ•°æ®

**æ­¥éª¤ 1ï¼šæœ¬åœ°ç”Ÿæˆæ•°æ®**

ä½¿ç”¨é¡¹ç›®çš„æ•°æ®ç®¡é“ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼š

```bash
# åœ¨æœ¬åœ°æ‰§è¡Œ
export RAW_DATA_DIR="./raw_data"
export OPENAI_API_KEY="your-api-key"
bash scripts/run_data_pipeline.sh
```

ç”Ÿæˆçš„æ–‡ä»¶ï¼š
- `example/clara_training_data.jsonl` - åŒ…å«æ‰€æœ‰æ•°æ®

**æ­¥éª¤ 2ï¼šåˆ†å‰²æ•°æ®**

```python
# split_data.py
import json

with open('example/clara_training_data.jsonl', 'r') as f:
    all_data = [json.loads(line) for line in f]

# åˆ†å‰²æ•°æ®
pretrain_data = all_data[:len(all_data)//2]
instruction_data = all_data[len(all_data)//2:]
end_to_end_data = instruction_data

# ä¿å­˜
with open('pretrain_data.jsonl', 'w') as f:
    for item in pretrain_data:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')

with open('instruction_data.jsonl', 'w') as f:
    for item in instruction_data:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')

with open('end_to_end_data.jsonl', 'w') as f:
    for item in end_to_end_data:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')
```

**æ­¥éª¤ 3ï¼šä¸Šä¼ åˆ° Colab**

åœ¨ notebook çš„æ•°æ®å‡†å¤‡éƒ¨åˆ†ï¼Œå–æ¶ˆæ³¨é‡Šä¸Šä¼ ä»£ç ï¼š

```python
from google.colab import files
uploaded = files.upload()  # é€‰æ‹©ä½ çš„ .jsonl æ–‡ä»¶
```

### æ•°æ®è´¨é‡è¦æ±‚

**æ¯ä¸ªé˜¶æ®µæœ€å°‘æ•°æ®é‡ï¼š**
- Stage 1: 100+ QA å¯¹
- Stage 2: 50+ é—®ç­”å¯¹
- Stage 3: 50+ é—®ç­”å¯¹

**æ¨èæ•°æ®é‡ï¼š**
- å°è§„æ¨¡æµ‹è¯•: 200-500 æ ·æœ¬
- ä¸­ç­‰è§„æ¨¡: 1,000-5,000 æ ·æœ¬
- å¤§è§„æ¨¡è®­ç»ƒ: 10,000+ æ ·æœ¬

---

## âš™ï¸ è®­ç»ƒé…ç½®

### è‡ªåŠ¨é…ç½®

Notebook ä¼šæ ¹æ® GPU å†…å­˜è‡ªåŠ¨è°ƒæ•´å‚æ•°ï¼š

```python
# T4 (16GB)
TRAIN_BATCH_SIZE = 32
MICRO_BATCH_SIZE = 1
MAX_SAMPLES = 200

# V100/A100-40GB
TRAIN_BATCH_SIZE = 64
MICRO_BATCH_SIZE = 2
MAX_SAMPLES = 500

# A100-80GB
TRAIN_BATCH_SIZE = 128
MICRO_BATCH_SIZE = 2
MAX_SAMPLES = 1000
```

### æ‰‹åŠ¨è°ƒæ•´

å¦‚æœé‡åˆ° OOMï¼ˆå†…å­˜ä¸è¶³ï¼‰ï¼Œåœ¨é…ç½®å•å…ƒæ ¼ä¸­ä¿®æ”¹ï¼š

```python
# å‡å°æ‰¹æ¬¡å¤§å°
TRAIN_BATCH_SIZE = 16  # ä» 32 å‡å°
MICRO_BATCH_SIZE = 1   # ä¿æŒæœ€å°

# å‡å°‘è®­ç»ƒæ ·æœ¬
MAX_SAMPLES = 100  # ä» 200 å‡å°

# å‡å°åºåˆ—é•¿åº¦
MAX_LEN = 1024  # ä» 2048 å‡å°
```

### å…¶ä»–é‡è¦å‚æ•°

```python
# å­¦ä¹ ç‡
LEARNING_RATE = 1e-4  # é»˜è®¤å€¼ï¼Œå¯è°ƒæ•´ä¸º 5e-5 æˆ– 2e-4

# å‹ç¼©ç‡
COMPRESS_RATE = 32  # å¯é€‰: 16, 32, 64

# æ–‡æ¡£æœ€å¤§é•¿åº¦
DOC_MAX_LENGTH = 256  # æ ¹æ®æ–‡æ¡£é•¿åº¦è°ƒæ•´
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: è¿è¡Œæ—¶æ–­å¼€è¿æ¥

**é—®é¢˜ï¼š** Colab ç©ºé—² 90 åˆ†é’Ÿåæ–­å¼€

**è§£å†³æ–¹æ¡ˆï¼š**
1. **ä½¿ç”¨ Colab Pro**ï¼šæ›´é•¿çš„è¿è¡Œæ—¶é—´
2. **å®šæœŸäº¤äº’**ï¼šæ¯å°æ—¶ç‚¹å‡»ä¸€æ¬¡é¡µé¢
3. **ä¿å­˜æ£€æŸ¥ç‚¹**ï¼š
```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ 
--save_steps 50  # æ¯ 50 æ­¥ä¿å­˜
```

### Q2: Out of Memory (OOM)

**é”™è¯¯ä¿¡æ¯ï¼š** `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# 1. å‡å°æ‰¹æ¬¡å¤§å°
TRAIN_BATCH_SIZE = 16
MICRO_BATCH_SIZE = 1

# 2. å‡å°‘æœ€å¤§æ ·æœ¬æ•°
MAX_SAMPLES = 100

# 3. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆå·²é»˜è®¤å¯ç”¨ï¼‰
--gradient_checkpointing

# 4. å‡å°åºåˆ—é•¿åº¦
MAX_LEN = 1024
```

### Q3: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢

**ä¼˜åŒ–æ–¹æ³•ï¼š**

1. **å®‰è£… Flash Attention**
```python
# åœ¨ä¾èµ–å®‰è£…éƒ¨åˆ†å–æ¶ˆæ³¨é‡Š
!pip install flash-attn --no-build-isolation
USE_FLASH_ATTN = True
```

2. **ä½¿ç”¨æ›´å¿«çš„ GPU**
- å‡çº§åˆ° Colab Pro
- é€‰æ‹© V100 æˆ– A100

3. **å‡å°‘æ•°æ®é‡**
```python
MAX_SAMPLES = 200  # ç”¨äºæµ‹è¯•
```

### Q4: æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥

**é”™è¯¯ï¼š** `FileNotFoundError` æˆ– `Checkpoint not found`

**æ£€æŸ¥ï¼š**
```bash
# éªŒè¯æ£€æŸ¥ç‚¹å­˜åœ¨
!ls -lh /content/checkpoints/clara_stage1/

# æ£€æŸ¥ç£ç›˜ç©ºé—´
!df -h
```

**è§£å†³ï¼š**
- ç¡®ä¿ä¸Šä¸€é˜¶æ®µè®­ç»ƒå®Œæˆ
- æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿç£ç›˜ç©ºé—´ï¼ˆéœ€è¦ 20-30GBï¼‰

### Q5: Flash Attention å®‰è£…å¤±è´¥

**é—®é¢˜ï¼š** ç¼–è¯‘é”™è¯¯æˆ–è¶…æ—¶

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# è·³è¿‡ flash-attnï¼Œä½¿ç”¨æ ‡å‡† attention
USE_FLASH_ATTN = False
FLASH_ATTN_FLAG = ''

# è®­ç»ƒä»å¯æ­£å¸¸è¿›è¡Œï¼Œé€Ÿåº¦ç•¥æ…¢ 10-15%
```

### Q6: æ•°æ®æ ¼å¼é”™è¯¯

**é”™è¯¯ï¼š** `JSONDecodeError` æˆ– `KeyError`

**æ£€æŸ¥æ•°æ®æ ¼å¼ï¼š**
```python
import json

# éªŒè¯ JSONL æ–‡ä»¶
with open('pretrain_data.jsonl', 'r') as f:
    for i, line in enumerate(f):
        try:
            data = json.loads(line)
            print(f"Line {i}: {list(data.keys())}")
        except Exception as e:
            print(f"Error at line {i}: {e}")
            break
```

**æ ‡å‡†æ ¼å¼ï¼š**
- Stage 1: `data_type`, `question`, `answers`, `docs`
- Stage 2/3: `question`, `docs`, `gold_answer`

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–

### åŠ é€Ÿè®­ç»ƒçš„æ–¹æ³•

#### 1. Flash Attentionï¼ˆæ¨èï¼‰

**åŠ é€Ÿï¼š** 10-15%
**å®‰è£…ï¼š**
```bash
pip install flash-attn --no-build-isolation
```

#### 2. ä½¿ç”¨æ›´å¿«çš„ GPU

| GPU | ç›¸å¯¹é€Ÿåº¦ | ä»·æ ¼ |
|-----|---------|------|
| T4 | 1x | å…è´¹ |
| V100 | 2x | Pro |
| A100-40GB | 3x | Pro+ |
| A100-80GB | 4x | Pro+ |

#### 3. æ‰¹æ¬¡å¤§å°ä¼˜åŒ–

```python
# æ‰¾åˆ°æœ€å¤§å¯ç”¨æ‰¹æ¬¡å¤§å°
for batch_size in [32, 64, 96, 128]:
    try:
        TRAIN_BATCH_SIZE = batch_size
        # è¿è¡Œè®­ç»ƒ...
        print(f"Success with batch_size={batch_size}")
        break
    except RuntimeError as e:
        if "out of memory" in str(e):
            continue
```

#### 4. æ··åˆç²¾åº¦è®­ç»ƒ

```bash
# å·²é»˜è®¤å¯ç”¨ bfloat16
--bf16

# å¦‚æœ GPU ä¸æ”¯æŒï¼Œä½¿ç”¨ float16
--fp16
```

### æˆæœ¬ä¼˜åŒ–

#### å…è´¹ç‰ˆ Colab

**é™åˆ¶ï¼š**
- T4 GPU
- 12 å°æ—¶è¿è¡Œæ—¶
- å¯èƒ½æ’é˜Ÿç­‰å¾…

**é€‚ç”¨äºï¼š**
- æµ‹è¯•æµç¨‹
- å°è§„æ¨¡æ•°æ®ï¼ˆ<500 æ ·æœ¬ï¼‰
- å­¦ä¹ å’Œå®éªŒ

#### Colab Pro ($10/æœˆ)

**ä¼˜åŠ¿ï¼š**
- V100 æˆ– A100 GPU
- 24 å°æ—¶è¿è¡Œæ—¶
- ä¼˜å…ˆè®¿é—®
- æ›´å¤š RAM

**é€‚ç”¨äºï¼š**
- æ­£å¼è®­ç»ƒ
- ä¸­å¤§è§„æ¨¡æ•°æ®ï¼ˆ1000+ æ ·æœ¬ï¼‰
- ç”Ÿäº§æ¨¡å‹

#### è®¡ç®—å•å…ƒä¼°ç®—

**å…è´¹ç‰ˆï¼š**
- Stage 1: 30-60 åˆ†é’Ÿ
- Stage 2: 30-60 åˆ†é’Ÿ
- Stage 3: 45-90 åˆ†é’Ÿ
- **æ€»è®¡ï¼š** 2-3 å°æ—¶

**Pro (A100):**
- Stage 1: 10-20 åˆ†é’Ÿ
- Stage 2: 10-20 åˆ†é’Ÿ
- Stage 3: 15-30 åˆ†é’Ÿ
- **æ€»è®¡ï¼š** 40-70 åˆ†é’Ÿ

---

## ğŸ“¤ æ¨¡å‹å¯¼å‡º

### æ–¹æ³• 1ï¼šä¸‹è½½åˆ°æœ¬åœ°

```python
# åˆ›å»ºå‹ç¼©åŒ…
!cd /content/checkpoints && \
  zip -r clara_final.zip clara_stage3_final/

# ä¸‹è½½
from google.colab import files
files.download('/content/checkpoints/clara_final.zip')
```

**æ–‡ä»¶å¤§å°ï¼š** ~14GBï¼ˆMistral-7Bï¼‰

### æ–¹æ³• 2ï¼šä¿å­˜åˆ° Google Drive

```python
# æŒ‚è½½ Drive
from google.colab import drive
drive.mount('/content/drive')

# å¤åˆ¶æ¨¡å‹
!cp -r /content/checkpoints/clara_stage3_final \
  /content/drive/MyDrive/CLaRa_Models/

print('âœ… Model saved to Google Drive')
```

### æ–¹æ³• 3ï¼šä¸Šä¼ åˆ° HuggingFace Hub

```python
# å®‰è£… huggingface_hub
!pip install huggingface_hub

# ç™»å½•
from huggingface_hub import login
login()  # è¾“å…¥ä½ çš„ token

# ä¸Šä¼ æ¨¡å‹
from huggingface_hub import HfApi
api = HfApi()

api.upload_folder(
    folder_path="/content/checkpoints/clara_stage3_final",
    repo_id="your-username/clara-custom",
    repo_type="model"
)
```

---

## ğŸ§ª æ¨¡å‹æµ‹è¯•

### å¿«é€Ÿæ¨ç†æµ‹è¯•

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# åŠ è½½æ¨¡å‹
model_path = "/content/checkpoints/clara_stage3_final"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

# æµ‹è¯•é—®ç­”
def test_qa(question, document):
    prompt = f"Document: {document}\n\nQuestion: {question}\n\nAnswer:"
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    outputs = model.generate(
        **inputs,
        max_new_tokens=100,
        temperature=0.7,
        do_sample=True
    )

    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# æµ‹è¯•
question = "What is CLaRa?"
document = "CLaRa is a framework for retrieval-augmented generation..."
answer = test_qa(question, document)
print(answer)
```

### æ‰¹é‡è¯„ä¼°

```python
# å‡†å¤‡æµ‹è¯•é›†
test_data = [
    {"question": "Q1", "doc": "Doc1", "expected": "A1"},
    {"question": "Q2", "doc": "Doc2", "expected": "A2"},
]

# è¯„ä¼°
results = []
for item in test_data:
    pred = test_qa(item["question"], item["doc"])
    results.append({
        "question": item["question"],
        "expected": item["expected"],
        "predicted": pred
    })

# æ˜¾ç¤ºç»“æœ
import pandas as pd
df = pd.DataFrame(results)
print(df)
```

---

## ğŸ“š é«˜çº§ä½¿ç”¨

### è‡ªå®šä¹‰è®­ç»ƒå‚æ•°

ç¼–è¾‘é…ç½®å•å…ƒæ ¼ï¼Œä¿®æ”¹è®­ç»ƒå‚æ•°ï¼š

```python
# è®­ç»ƒè½®æ•°
MAX_EPOCHS = 3  # å¢åŠ åˆ° 3 è½®

# å­¦ä¹ ç‡è¡°å‡
LEARNING_RATE = 2e-4  # è°ƒæ•´å­¦ä¹ ç‡
LR_SCHEDULER = 'cosine'  # æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦

# å‹ç¼©ç‡å®éªŒ
COMPRESS_RATE = 64  # å°è¯• 64 å€å‹ç¼©

# æ›´é¢‘ç¹çš„ä¿å­˜
SAVE_STEPS = 50  # æ¯ 50 æ­¥ä¿å­˜ä¸€æ¬¡

# å¯ç”¨ WandB æ—¥å¿—
USE_WANDB = True
WANDB_PROJECT = "clara-training"
```

### æ–­ç‚¹ç»­è®­

å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥ä»æ£€æŸ¥ç‚¹ç»§ç»­ï¼š

```python
# æ¢å¤ Stage 1
!torchrun ... \
    --ckpt_path /content/checkpoints/clara_stage1 \
    --resume_training

# æˆ–æ‰‹åŠ¨æŒ‡å®š step
--resume_from_checkpoint /path/to/checkpoint-100
```

### å¤š GPU è®­ç»ƒ

è™½ç„¶ Colab é€šå¸¸åªæœ‰å• GPUï¼Œä½†ä»£ç æ”¯æŒå¤š GPUï¼š

```python
# æ£€æµ‹ GPU æ•°é‡
NUM_GPUS = torch.cuda.device_count()
print(f"Available GPUs: {NUM_GPUS}")

# è‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰ GPU
!torchrun --nproc_per_node={NUM_GPUS} ...
```

---

## ğŸ”— ç›¸å…³èµ„æº

### æ–‡æ¡£
- [README.md](README.md) - é¡¹ç›®ä¸»æ–‡æ¡£
- [DATA_PIPELINE_GUIDE.md](DATA_PIPELINE_GUIDE.md) - æ•°æ®å¤„ç†æŒ‡å—
- [FLASH_ATTN_FIX.md](FLASH_ATTN_FIX.md) - Flash Attention é—®é¢˜è§£å†³

### æ¨¡å‹
- [CLaRa-Base](https://huggingface.co/probejie/CLaRa-Base) - åŸºç¡€æ¨¡å‹
- [CLaRa-Instruct](https://huggingface.co/probejie/CLaRa-Instruct) - æŒ‡ä»¤æ¨¡å‹
- [CLaRa-E2E](https://huggingface.co/probejie/CLaRa-End-to-end) - ç«¯åˆ°ç«¯æ¨¡å‹

### è®ºæ–‡
- [arXiv Paper](https://arxiv.org/abs/2511.18659) - CLaRa è®ºæ–‡

---

## ğŸ’¡ æœ€ä½³å®è·µ

### è®­ç»ƒæµç¨‹å»ºè®®

1. **é¦–æ¬¡è¿è¡Œ**
   - ä½¿ç”¨ç¤ºä¾‹æ•°æ®
   - T4 GPU å…è´¹ç‰ˆ
   - MAX_SAMPLES = 100-200
   - éªŒè¯æµç¨‹æ­£ç¡®æ€§

2. **æ•°æ®éªŒè¯**
   - ä¸Šä¼ å°‘é‡è‡ªå·±çš„æ•°æ®ï¼ˆ100 æ¡ï¼‰
   - è¿è¡Œå®Œæ•´ 3 é˜¶æ®µ
   - æ£€æŸ¥æ¨¡å‹è¾“å‡ºè´¨é‡

3. **æ­£å¼è®­ç»ƒ**
   - å‡†å¤‡å®Œæ•´æ•°æ®é›†
   - å‡çº§åˆ° Colab Pro
   - ä½¿ç”¨ A100 GPU
   - MAX_SAMPLES = 1000+

### æˆæœ¬æ§åˆ¶

**å…è´¹ç­–ç•¥ï¼š**
- åˆ†å¤šæ¬¡è®­ç»ƒï¼ˆæ¯æ¬¡ <2 å°æ—¶ï¼‰
- ä½¿ç”¨å°æ•°æ®é›†æµ‹è¯•
- åœ¨æœ¬åœ°å‡†å¤‡æ•°æ®

**ä»˜è´¹ä¼˜åŒ–ï¼š**
- é›†ä¸­æ—¶é—´è®­ç»ƒ
- ä½¿ç”¨ A100 å¿«é€Ÿå®Œæˆ
- å¼€å¯ WandB ç›‘æ§ï¼Œé¿å…æµªè´¹è®¡ç®—

### æ•°æ®å‡†å¤‡å»ºè®®

1. **æœ¬åœ°å¤„ç†**
   - åœ¨æœ¬åœ°ç”Ÿæˆæ‰€æœ‰æ•°æ®
   - éªŒè¯æ•°æ®æ ¼å¼å’Œè´¨é‡
   - å‹ç¼©åä¸Šä¼ åˆ° Colab

2. **æ•°æ®åˆ†å‰²**
   - é¢„ç•™ 10% ä½œä¸ºéªŒè¯é›†
   - ç¡®ä¿æ•°æ®å¤šæ ·æ€§
   - å¹³è¡¡å„ç±»åˆ«æ ·æœ¬

3. **è´¨é‡æ§åˆ¶**
   - æ£€æŸ¥ QA å¯¹çš„ç›¸å…³æ€§
   - è¿‡æ»¤ä½è´¨é‡æ ·æœ¬
   - ç¡®ä¿æ–‡æ¡£é•¿åº¦é€‚å½“

---

## ğŸ†˜ è·å–å¸®åŠ©

**é‡åˆ°é—®é¢˜ï¼Ÿ**

1. æ£€æŸ¥æœ¬æ–‡æ¡£çš„ [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜) éƒ¨åˆ†
2. æŸ¥çœ‹ [GitHub Issues](https://github.com/apple/ml-clara/issues)
3. é˜…è¯» [FLASH_ATTN_FIX.md](FLASH_ATTN_FIX.md)

**æŠ¥å‘Š Bugï¼š**
- æä¾›å®Œæ•´é”™è¯¯ä¿¡æ¯
- è¯´æ˜ GPU å‹å·å’Œ RAM
- åŒ…å«æ•°æ®æ ¼å¼ç¤ºä¾‹
- æè¿°å¤ç°æ­¥éª¤

---

## âœ… æ£€æŸ¥æ¸…å•

è®­ç»ƒå‰ç¡®è®¤ï¼š
- [ ] GPU è¿è¡Œæ—¶å·²å¯ç”¨
- [ ] High-RAM å·²é€‰æ‹©ï¼ˆæ¨èï¼‰
- [ ] æ•°æ®æ–‡ä»¶å·²å‡†å¤‡å¥½
- [ ] ç£ç›˜ç©ºé—´å……è¶³ï¼ˆ30GB+ï¼‰
- [ ] ç½‘ç»œè¿æ¥ç¨³å®š

è®­ç»ƒåéªŒè¯ï¼š
- [ ] ä¸‰ä¸ªé˜¶æ®µéƒ½æˆåŠŸå®Œæˆ
- [ ] æ£€æŸ¥ç‚¹æ–‡ä»¶å­˜åœ¨
- [ ] æ¨¡å‹å¯ä»¥åŠ è½½
- [ ] æ¨ç†è¾“å‡ºåˆç†
- [ ] æ¨¡å‹å·²å¯¼å‡º/å¤‡ä»½

---

**ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-12-01
**é€‚ç”¨äº**: CLaRa v1.0 + Google Colab

**åˆ¶ä½œ**: CLaRa Team with â¤ï¸

å¦‚æœè¿™ä¸ªæŒ‡å—å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™é¡¹ç›®ä¸€ä¸ª â­ï¼
