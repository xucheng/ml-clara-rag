# Top-K Data Synthesis - Implementation Summary

## é—®é¢˜åˆ†æ

åŸå§‹çš„ `synthesize_data.py` è„šæœ¬ä¸ºæ¯ä¸ªé—®é¢˜åªç”Ÿæˆ 1 ä¸ªæ–‡æ¡£ï¼š

```python
# ç¬¬ 151 è¡Œ
qa_entry = {
    "question": qa.get("question"),
    "docs": [chunk],  # âŒ åªæœ‰ 1 ä¸ªæ–‡æ¡£
    "gold_answer": qa.get("answer")
}
```

è¿™å¯¼è‡´ï¼š
- âœ… æ”¯æŒ `generation_top_k=1` è®­ç»ƒ
- âŒ ä¸æ”¯æŒ `generation_top_k > 1` è®­ç»ƒï¼ˆä¼šæŠ¥é”™ï¼‰
- âŒ æ¨¡å‹æ— æ³•å­¦ä¹ æ–‡æ¡£æ’åºå’Œå¤šæ–‡æ¡£èåˆ

---

## è§£å†³æ–¹æ¡ˆ

åˆ›å»ºäº†å¢å¼ºç‰ˆæ•°æ®åˆæˆè„šæœ¬ `synthesize_data_topk.py`ï¼Œæ”¯æŒä¸ºæ¯ä¸ªé—®é¢˜ç”Ÿæˆå¤šä¸ªå€™é€‰æ–‡æ¡£ã€‚

### æ ¸å¿ƒæ”¹è¿›

1. **å¯é…ç½® Top-K å€¼**: é€šè¿‡ `--target_top_k` å‚æ•°è®¾ç½®ï¼ˆ1-10ï¼‰
2. **ä¸¤ç§è´Ÿæ ·æœ¬ç­–ç•¥**:
   - éšæœºé‡‡æ ·ï¼ˆé»˜è®¤ï¼‰: å¿«é€Ÿã€ä½æˆæœ¬
   - ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜ï¼ˆ`--use_embeddings`ï¼‰: é«˜è´¨é‡ã€åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦
3. **è‡ªåŠ¨æ–‡æ¡£æ··æ’**: æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬éšæœºæ‰“ä¹±
4. **å‘åå…¼å®¹**: `--target_top_k 1` æ—¶è¡Œä¸ºä¸åŸè„šæœ¬ç›¸åŒ

---

## åˆ›å»ºçš„æ–‡ä»¶

### 1. æ ¸å¿ƒè„šæœ¬

| æ–‡ä»¶ | ä½œç”¨ | è¡Œæ•° |
|------|------|------|
| **scripts/synthesize_data_topk.py** | å¢å¼ºç‰ˆæ•°æ®åˆæˆè„šæœ¬ | 295 è¡Œ |
| **scripts/validate_topk_data.py** | æ•°æ®æ ¼å¼éªŒè¯å·¥å…· | 175 è¡Œ |
| **scripts/run_data_pipeline_topk5.sh** | å®Œæ•´ pipeline è‡ªåŠ¨åŒ–è„šæœ¬ | 85 è¡Œ |

### 2. æ–‡æ¡£

| æ–‡ä»¶ | å†…å®¹ | å­—æ•° |
|------|------|------|
| **TOPK_DATA_SYNTHESIS_GUIDE.md** | è¯¦ç»†æŠ€æœ¯æŒ‡å— | ~4000 å­— |
| **TOPK_QUICKSTART.md** | å¿«é€Ÿä¸Šæ‰‹æŒ‡å— | ~2000 å­— |
| **TOPK_IMPLEMENTATION_SUMMARY.md** | å®ç°æ€»ç»“ï¼ˆæœ¬æ–‡æ¡£ï¼‰ | ~1000 å­— |

### 3. README æ›´æ–°

åœ¨ README.md çš„ "Data Pipeline" éƒ¨åˆ†æ·»åŠ äº† "Advanced: Top-K Data Synthesis" å°èŠ‚ã€‚

---

## ä½¿ç”¨æ–¹æ³•

### åŸºç¡€ç”¨æ³•ï¼ˆéšæœºè´Ÿæ ·æœ¬ï¼‰

```bash
python scripts/synthesize_data_topk.py \
    --input_file example/raw_knowledge.jsonl \
    --output_dir example \
    --api_key $OPENAI_API_KEY \
    --target_top_k 5
```

**ä¼˜ç‚¹**: ğŸš€ å¿«é€Ÿã€ğŸ’° æˆæœ¬ä½
**ç¼ºç‚¹**: è´Ÿæ ·æœ¬è´¨é‡ä¸€èˆ¬

### é«˜çº§ç”¨æ³•ï¼ˆç¡¬è´Ÿæ ·æœ¬æŒ–æ˜ï¼‰

```bash
python scripts/synthesize_data_topk.py \
    --input_file example/raw_knowledge.jsonl \
    --output_dir example \
    --api_key $OPENAI_API_KEY \
    --base_url https://api.openai.com/v1 \
    --model gpt-4o-mini \
    --target_top_k 5 \
    --use_embeddings
```

**ä¼˜ç‚¹**: ğŸ¯ é«˜è´¨é‡è´Ÿæ ·æœ¬ã€ğŸ§  æ›´å¼ºè®­ç»ƒä¿¡å·
**ç¼ºç‚¹**: ğŸŒ é€Ÿåº¦æ…¢ã€ğŸ’¸ æˆæœ¬é«˜

### éªŒè¯æ•°æ®

```bash
python scripts/validate_topk_data.py \
    --input_file example/end_to_end_data.jsonl \
    --expected_top_k 5
```

### å®Œæ•´ Pipeline

```bash
TARGET_TOP_K=5 USE_EMBEDDINGS=true bash scripts/run_data_pipeline_topk5.sh
```

---

## æŠ€æœ¯ç»†èŠ‚

### è´Ÿæ ·æœ¬é‡‡æ ·ç­–ç•¥

#### éšæœºé‡‡æ ·ï¼ˆé»˜è®¤ï¼‰

```python
available_indices = [i for i in range(len(all_chunks)) if i != positive_chunk_idx]
negative_indices = random.sample(available_indices, num_negatives)
negative_docs = [all_chunks[i] for i in negative_indices]
```

**ç‰¹ç‚¹**: 
- O(n) æ—¶é—´å¤æ‚åº¦
- è´Ÿæ ·æœ¬å¯èƒ½å®Œå…¨æ— å…³
- é€‚åˆæ–‡æ¡£æ•°é‡ > 20 çš„åœºæ™¯

#### ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜ï¼ˆ`--use_embeddings`ï¼‰

```python
# 1. ä¸ºæ‰€æœ‰æ–‡æ¡£ç”Ÿæˆ embeddings
chunk_embeddings = [get_embedding(client, chunk) for chunk in chunks]

# 2. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
similarities = [
    (i, cosine_similarity(positive_emb, chunk_emb))
    for i, chunk_emb in enumerate(chunk_embeddings)
    if i != positive_idx
]

# 3. é€‰æ‹© Top-N æœ€ç›¸ä¼¼çš„æ–‡æ¡£ä½œä¸ºè´Ÿæ ·æœ¬
similarities.sort(key=lambda x: x[1], reverse=True)
negative_indices = [idx for idx, _ in similarities[:num_negatives]]
```

**ç‰¹ç‚¹**:
- O(nÂ²) æ—¶é—´å¤æ‚åº¦ï¼ˆéœ€è¦è®¡ç®—æ‰€æœ‰ pairsï¼‰
- è´Ÿæ ·æœ¬è¯­ä¹‰ç›¸ä¼¼ä½†ä¸åŒ…å«ç­”æ¡ˆ
- è®­ç»ƒæ›´å…·æŒ‘æˆ˜æ€§
- éœ€è¦ OpenAI embedding APIï¼ˆ`text-embedding-3-small`ï¼‰

### æ•°æ®æ ¼å¼å¯¹æ¯”

**è¾“å…¥æ ¼å¼ï¼ˆraw_knowledge.jsonlï¼‰**:
```json
{
  "filename": "doc1.pdf",
  "content": "Gradient descent is an optimization algorithm..."
}
```

**è¾“å‡ºæ ¼å¼ï¼ˆend_to_end_data.jsonl, top-k=5ï¼‰**:
```json
{
  "question": "What is gradient descent?",
  "docs": [
    "Neural networks consist of layers...",          // è´Ÿæ ·æœ¬
    "Gradient descent is an optimization...",        // æ­£æ ·æœ¬
    "Learning rate controls the step size...",       // è´Ÿæ ·æœ¬
    "Batch normalization can accelerate training...", // è´Ÿæ ·æœ¬
    "Dropout randomly drops neurons..."              // è´Ÿæ ·æœ¬
  ],
  "gold_answer": "Gradient descent is..."
}
```

**å…³é”®ç‚¹**:
- `docs` æ•°ç»„é•¿åº¦ = `target_top_k`
- æ–‡æ¡£é¡ºåºéšæœºï¼ˆæ¨¡æ‹ŸçœŸå®æ£€ç´¢ç»“æœï¼‰
- è‡³å°‘ 1 ä¸ªæ­£æ ·æœ¬ï¼ˆèƒ½å›ç­”é—®é¢˜çš„æ–‡æ¡£ï¼‰
- 2-4 ä¸ªè´Ÿæ ·æœ¬ï¼ˆä¸èƒ½å›ç­”é—®é¢˜ï¼‰

---

## è®­ç»ƒé…ç½®è°ƒæ•´

ä¿®æ”¹ Colab notebook æˆ–è®­ç»ƒè„šæœ¬ï¼š

```python
# è®­ç»ƒå‚æ•°å¿…é¡»ä¸æ•°æ®åŒ¹é…
--generation_top_k 5  # æ”¹ä¸ºä½ çš„ target_top_k å€¼
```

**é‡è¦**: CLaRa çš„è‡ªåŠ¨è°ƒæ•´é€»è¾‘ï¼ˆcommit 1b99307ï¼‰ä¼šç¡®ä¿å®‰å…¨ï¼š
```python
actual_top_k = min(self.generation_top_k, len(docs))
```

---

## æ€§èƒ½å½±å“

æ ¹æ® CLaRa è®ºæ–‡å’Œå®éªŒï¼š

| æŒ‡æ ‡ | Top-K=1 | Top-K=5 | Top-K=10 |
|------|---------|---------|----------|
| **è®­ç»ƒæ—¶é—´** | 1x | ~1.5x | ~2x |
| **æ˜¾å­˜å ç”¨** | 1x | ~1.3x | ~1.5x |
| **æ£€ç´¢å¬å›ç‡** | åŸºå‡† | +3-5% | +5-8% |
| **å¤šè·³æ¨ç†** | âŒ | âœ… | âœ…âœ… |

**æ¨èé…ç½®**: Top-K=5 (æœ€ä½³æ€§ä»·æ¯”)

---

## æ•°æ®è´¨é‡è¦æ±‚

### æ–‡æ¡£åº“è§„æ¨¡å»ºè®®

| æ–‡æ¡£æ•°é‡ | æ¨è Top-K | åŸå›  |
|----------|-----------|------|
| < 10 chunks | 1-2 | æ–‡æ¡£ä¸å¤Ÿï¼Œè´Ÿæ ·æœ¬ä¼šé‡å¤ |
| 10-50 chunks | 3-5 | è¶³å¤Ÿå¤šæ ·æ€§ |
| > 50 chunks | 5-10 | å¯ä»¥æŒ–æ˜é«˜è´¨é‡è´Ÿæ ·æœ¬ |

**ç»éªŒæ³•åˆ™**: `num_chunks >= target_top_k * 3`

### è´Ÿæ ·æœ¬è´¨é‡æ ‡å‡†

**å¥½çš„è´Ÿæ ·æœ¬** âœ…:
- ä¸»é¢˜ç›¸å…³ï¼ˆåŒä¸€é¢†åŸŸï¼‰
- ä¸åŒ…å«ç­”æ¡ˆä¿¡æ¯
- è¯­ä¹‰ç›¸ä¼¼åº¦ä¸­ç­‰ï¼ˆ0.3-0.7ï¼‰

**å·®çš„è´Ÿæ ·æœ¬** âŒ:
- å®Œå…¨æ— å…³ï¼ˆå¦‚ "Python is a programming language"ï¼‰
- åŒ…å«ç­”æ¡ˆï¼ˆæ¨¡å‹ä¼šæ··æ·†ï¼‰
- ä¸æ­£æ ·æœ¬å®Œå…¨ç›¸åŒ

---

## å¸¸è§é—®é¢˜

### Q1: æ•°æ®ä¸­æœ‰å¤šä¸ªæ–‡æ¡£ï¼Œä½†è®­ç»ƒè¿˜æ˜¯æŠ¥é”™ï¼Ÿ

**æ£€æŸ¥æ¸…å•**:
1. âœ… Colab ä»£ç æ˜¯æœ€æ–°çš„ï¼ˆ`!git pull`ï¼‰
2. âœ… `--generation_top_k` ä¸æ•°æ®ä¸­ `docs` æ•°ç»„é•¿åº¦ä¸€è‡´
3. âœ… æ•°æ®æ ¼å¼æ­£ç¡®ï¼ˆç”¨ `validate_topk_data.py` éªŒè¯ï¼‰

### Q2: ä½¿ç”¨ `--use_embeddings` æ—¶æŠ¥ 401 é”™è¯¯ï¼Ÿ

**åŸå› **: Embedding API éœ€è¦ OpenAI å®˜æ–¹ API

**è§£å†³**:
```bash
# ç¡®ä¿ä½¿ç”¨ OpenAI å®˜æ–¹ endpoint
--base_url https://api.openai.com/v1 \
--api_key sk-... # OpenAI API key
```

å¦‚æœä½¿ç”¨å…¶ä»– providerï¼ˆå¦‚ DashScopeï¼‰ï¼Œç§»é™¤ `--use_embeddings`ã€‚

### Q3: æ–‡æ¡£æ•°é‡ä¸ä¸€è‡´è­¦å‘Šï¼Ÿ

**è¾“å‡º**:
```
âš ï¸  Warning: Inconsistent document counts detected!
   Found 2 different document counts: [1, 5]
```

**åŸå› **: éƒ¨åˆ†æ•°æ®æ˜¯æ—§æ ¼å¼ï¼ˆtop-k=1ï¼‰ï¼Œéƒ¨åˆ†æ˜¯æ–°æ ¼å¼ï¼ˆtop-k=5ï¼‰

**è§£å†³**: é‡æ–°ç”Ÿæˆæ‰€æœ‰æ•°æ®
```bash
rm example/end_to_end_data.jsonl
python scripts/synthesize_data_topk.py --target_top_k 5 ...
```

---

## ä¸åŸå§‹è„šæœ¬å¯¹æ¯”

| ç‰¹æ€§ | synthesize_data.py | synthesize_data_topk.py |
|------|-------------------|------------------------|
| Top-K æ”¯æŒ | å›ºå®šä¸º 1 | 1-10 å¯é…ç½® |
| è´Ÿæ ·æœ¬ç­–ç•¥ | æ—  | éšæœº/ç¡¬è´Ÿæ ·æœ¬ |
| Embedding æ”¯æŒ | âŒ | âœ… |
| æ–‡æ¡£æ··æ’ | âŒ | âœ… |
| æ•°æ®éªŒè¯ | âŒ | âœ… (å•ç‹¬å·¥å…·) |
| å‘åå…¼å®¹ | - | âœ… |

---

## åç»­å·¥ä½œå»ºè®®

1. **å®éªŒä¸åŒ Top-K å€¼**: å°è¯• 3/5/8ï¼Œæ¯”è¾ƒæ•ˆæœ
2. **æ··åˆè´Ÿæ ·æœ¬ç­–ç•¥**: 70% ç¡¬è´Ÿæ ·æœ¬ + 30% éšæœºè´Ÿæ ·æœ¬
3. **åŠ¨æ€ Top-K**: æ ¹æ®é—®é¢˜éš¾åº¦è°ƒæ•´å€™é€‰æ–‡æ¡£æ•°é‡
4. **è´Ÿæ ·æœ¬éš¾åº¦é€’å¢**: è®­ç»ƒåˆæœŸç®€å•è´Ÿæ ·æœ¬ï¼ŒåæœŸå›°éš¾è´Ÿæ ·æœ¬

---

## å‚è€ƒæ–‡æ¡£

- **å¿«é€Ÿä¸Šæ‰‹**: [TOPK_QUICKSTART.md](TOPK_QUICKSTART.md)
- **è¯¦ç»†æŒ‡å—**: [TOPK_DATA_SYNTHESIS_GUIDE.md](TOPK_DATA_SYNTHESIS_GUIDE.md)
- **è®­ç»ƒæŒ‡å—**: [COLAB_TRAINING_GUIDE.md](COLAB_TRAINING_GUIDE.md)
- **Data Pipeline**: [DATA_PIPELINE_GUIDE.md](DATA_PIPELINE_GUIDE.md)
- **README**: [../README.md](../README.md)

---

## è´¡çŒ®è€…

æœ¬å®ç°åŸºäº CLaRa è®ºæ–‡å’Œ OpenRLHF æ¡†æ¶ï¼Œæ„Ÿè°¢åŸä½œè€…çš„å·¥ä½œã€‚

**å®ç°æ—¥æœŸ**: 2025-12-03
**ç‰ˆæœ¬**: v1.0
